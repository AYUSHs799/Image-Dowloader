{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Jupiter Notebook is used to download images from Google Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the url for the google image search\n",
    "google_image = \"https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&\"\n",
    "\n",
    "# Creating the user agent\n",
    "user_agent = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36\"\n",
    "            }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the function to download the images\n",
    "def download_images(data = None, n_images = None, folder_name = 'Google_images_downloader'):\n",
    "\n",
    "    # Creating the directory to save the images\n",
    "    if data is None:\n",
    "        data = input('What are you looking for? ')\n",
    "\n",
    "    # Creating the directory to save the images\n",
    "    if n_images is None:\n",
    "        n_images = int(input('How many images do you want? '))\n",
    "\n",
    "    # Creating the directory to save the images\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "\n",
    "    print('searching...')\n",
    "\n",
    "    # Creating the directory to save the images\n",
    "    search_url = google_image + 'q=' + data\n",
    "\n",
    "    # Requesting the URL, without User-Agent the permission gets denied\n",
    "    response = requests.get(search_url, headers=user_agent)\n",
    "\n",
    "    # Getting the response in text format\n",
    "    html = response.text\n",
    "\n",
    "    # Passing the source code to BeautifulSoup to create a BeautifulSoup object for it.\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Extract all the <img> tags where class='rg_i Q4LuWd'\n",
    "    results = soup.findAll('img', {'class': 'rg_i Q4LuWd'})\n",
    "\n",
    "    # Extract the links from the tags extracted above\n",
    "    count = 1           # To count no. of images downloaded so far\n",
    "    links = []          # To store links of images.\n",
    "\n",
    "    for result in results:\n",
    "\n",
    "        # Checks if the current result contains the data-src attribute. \n",
    "        try:\n",
    "            \n",
    "            # Extract the link\n",
    "            link = result['data-src']\n",
    "\n",
    "            # Append the link to the links.\n",
    "            links.append(link)\n",
    "\n",
    "            # Increment the count and break if count greater than requested no. of images to download.\n",
    "            count += 1\n",
    "            if(count > n_images):\n",
    "                break\n",
    "        \n",
    "        # Handling the StaleElementReferenceException exception\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    # Downloading the requested images\n",
    "    print(f\"Downloading {len(links)} images...\")\n",
    "\n",
    "    # Toggling through the links and downloading them one by one.\n",
    "    for i, link in enumerate(links):\n",
    "\n",
    "        # dowlnoading the image\n",
    "        response = requests.get(link)\n",
    "\n",
    "        # Saving the image to the directory\n",
    "        image_name = folder_name + '/' + data + str(i+1) + '.jpg'\n",
    "\n",
    "        # Writing the image\n",
    "        with open(image_name, 'wb') as fh:\n",
    "            fh.write(response.content)\n",
    "\n",
    "    print('Download completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching...\n",
      "Downloading 6 images...\n",
      "Download completed!\n"
     ]
    }
   ],
   "source": [
    "# Calling the function\n",
    "download_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching...\n",
      "Downloading 10 images...\n",
      "Download completed!\n"
     ]
    }
   ],
   "source": [
    "download_images(data = 'Anaconda', n_images = 10, folder_name = 'Anaconda_Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
